{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Lake Pipeline of US-Immigration 2016\n",
    "\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "Spark is used to build a data lake pipeline with the datasets listed below.\n",
    "\n",
    "* US I94 immigration\n",
    "* airports\n",
    "* airline\n",
    "* US cities demographic data\n",
    "* world temperature data\n",
    "\n",
    "#### Project Steps\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required packages.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.cleaning import *\n",
    "from utils.common import *\n",
    "from utils.loading import *\n",
    "from utils.modeling import *\n",
    "from utils.quality_checking import *\n",
    "from utils.transforming import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spark session.\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "\n",
    "The goal of this project is to provide a ETL pipeline of immigration datasets with some additional datasets.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "1. I94 Immigration Data: This data comes from the US National Tourism and Trade Office. [link](https://travel.trade.gov/research/reports/i94/historical/2016.html) **Only the i94_apr16_sub.sas7bdat will be used in this project.**\n",
    "2. World Temperature Data: This dataset came from Kaggle. You can read more about it. [link](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)\n",
    "3. U.S. City Demographic Data: This data comes from OpenSoft. You can read more about it. [link](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)\n",
    "4. Airport Code Table: This is a simple table of airport codes and corresponding cities from data hub. [link](https://datahub.io/core/airport-codes#data)\n",
    "5. Countries: This dataset is extracted from `I94_SAS_Labels_Descriptions.SAS` provided by Udacity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "\n",
    "1. Explore the datasets, we have datasets in csv, json and parquet format.\n",
    "2. Clean the datasets.\n",
    "3. Transform the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Explore the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 2891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>city</th>\n",
       "      <th>count</th>\n",
       "      <th>female_population</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>male_population</th>\n",
       "      <th>median_age</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>race</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>total_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.56</td>\n",
       "      <td>Wichita</td>\n",
       "      <td>8791</td>\n",
       "      <td>197601</td>\n",
       "      <td>40270.0</td>\n",
       "      <td>192354</td>\n",
       "      <td>34.6</td>\n",
       "      <td>23978.0</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>KS</td>\n",
       "      <td>389955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.67</td>\n",
       "      <td>Allen</td>\n",
       "      <td>22304</td>\n",
       "      <td>59581</td>\n",
       "      <td>19652.0</td>\n",
       "      <td>60626</td>\n",
       "      <td>33.5</td>\n",
       "      <td>5691.0</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "      <td>120207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.74</td>\n",
       "      <td>Danbury</td>\n",
       "      <td>8454</td>\n",
       "      <td>41227</td>\n",
       "      <td>25675.0</td>\n",
       "      <td>43435</td>\n",
       "      <td>37.3</td>\n",
       "      <td>3752.0</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>CT</td>\n",
       "      <td>84662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.39</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>67526</td>\n",
       "      <td>340365</td>\n",
       "      <td>88193.0</td>\n",
       "      <td>314231</td>\n",
       "      <td>34.1</td>\n",
       "      <td>27942.0</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>TN</td>\n",
       "      <td>654596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.70</td>\n",
       "      <td>Stamford</td>\n",
       "      <td>11013</td>\n",
       "      <td>63936</td>\n",
       "      <td>44003.0</td>\n",
       "      <td>64941</td>\n",
       "      <td>35.4</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>CT</td>\n",
       "      <td>128877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>335559</td>\n",
       "      <td>186829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155408</td>\n",
       "      <td>41.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>342237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.28</td>\n",
       "      <td>Provo</td>\n",
       "      <td>108471</td>\n",
       "      <td>59027</td>\n",
       "      <td>10925.0</td>\n",
       "      <td>56231</td>\n",
       "      <td>23.6</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Utah</td>\n",
       "      <td>UT</td>\n",
       "      <td>115258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.13</td>\n",
       "      <td>San Marcos</td>\n",
       "      <td>4447</td>\n",
       "      <td>47688</td>\n",
       "      <td>21558.0</td>\n",
       "      <td>45246</td>\n",
       "      <td>35.4</td>\n",
       "      <td>5189.0</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>92934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.27</td>\n",
       "      <td>Escondido</td>\n",
       "      <td>3151</td>\n",
       "      <td>74907</td>\n",
       "      <td>46298.0</td>\n",
       "      <td>76551</td>\n",
       "      <td>33.3</td>\n",
       "      <td>8110.0</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>151458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>76349</td>\n",
       "      <td>42265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34743</td>\n",
       "      <td>40.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>77008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_household_size        city   count  female_population  \\\n",
       "0                    2.56     Wichita    8791             197601   \n",
       "1                    2.67       Allen   22304              59581   \n",
       "2                    2.74     Danbury    8454              41227   \n",
       "3                    2.39   Nashville   67526             340365   \n",
       "4                    2.70    Stamford   11013              63936   \n",
       "5                     NaN    San Juan  335559             186829   \n",
       "6                    3.28       Provo  108471              59027   \n",
       "7                    3.13  San Marcos    4447              47688   \n",
       "8                    3.27   Escondido    3151              74907   \n",
       "9                     NaN      Caguas   76349              42265   \n",
       "\n",
       "   foreign_born  male_population  median_age  number_of_veterans  \\\n",
       "0       40270.0           192354        34.6             23978.0   \n",
       "1       19652.0            60626        33.5              5691.0   \n",
       "2       25675.0            43435        37.3              3752.0   \n",
       "3       88193.0           314231        34.1             27942.0   \n",
       "4       44003.0            64941        35.4              2269.0   \n",
       "5           NaN           155408        41.4                 NaN   \n",
       "6       10925.0            56231        23.6              2177.0   \n",
       "7       21558.0            45246        35.4              5189.0   \n",
       "8       46298.0            76551        33.3              8110.0   \n",
       "9           NaN            34743        40.4                 NaN   \n",
       "\n",
       "                                race         state state_code  \\\n",
       "0  American Indian and Alaska Native        Kansas         KS   \n",
       "1          Black or African-American  Pennsylvania         PA   \n",
       "2          Black or African-American   Connecticut         CT   \n",
       "3                 Hispanic or Latino     Tennessee         TN   \n",
       "4                              Asian   Connecticut         CT   \n",
       "5                 Hispanic or Latino   Puerto Rico         PR   \n",
       "6                              White          Utah         UT   \n",
       "7          Black or African-American    California         CA   \n",
       "8  American Indian and Alaska Native    California         CA   \n",
       "9                 Hispanic or Latino   Puerto Rico         PR   \n",
       "\n",
       "   total_population  \n",
       "0            389955  \n",
       "1            120207  \n",
       "2             84662  \n",
       "3            654596  \n",
       "4            128877  \n",
       "5            342237  \n",
       "6            115258  \n",
       "7             92934  \n",
       "8            151458  \n",
       "9             77008  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics = load_json(spark=spark, path='data/us-cities-demographics.json').select('fields.*')\n",
    "print_data(demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 55075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>None</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>3810</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>None</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>-112.16500091552734, 34.305599212646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00CA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldstone /Gts/ Airport</td>\n",
       "      <td>3038</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Barstow</td>\n",
       "      <td>00CA</td>\n",
       "      <td>None</td>\n",
       "      <td>00CA</td>\n",
       "      <td>-116.888000488, 35.350498199499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00CL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Williams Ag Airport</td>\n",
       "      <td>87</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>00CL</td>\n",
       "      <td>None</td>\n",
       "      <td>00CL</td>\n",
       "      <td>-121.763427, 39.427188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00CN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Kitchen Creek Helibase Heliport</td>\n",
       "      <td>3350</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>00CN</td>\n",
       "      <td>None</td>\n",
       "      <td>00CN</td>\n",
       "      <td>-116.4597417, 32.7273736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "5  00AS  small_airport                      Fulton Airport         1100   \n",
       "6  00AZ  small_airport                      Cordes Airport         3810   \n",
       "7  00CA  small_airport             Goldstone /Gts/ Airport         3038   \n",
       "8  00CL  small_airport                 Williams Ag Airport           87   \n",
       "9  00CN       heliport     Kitchen Creek Helibase Heliport         3350   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "5        NA          US      US-OK          Alex     00AS      None   \n",
       "6        NA          US      US-AZ        Cordes     00AZ      None   \n",
       "7        NA          US      US-CA       Barstow     00CA      None   \n",
       "8        NA          US      US-CA         Biggs     00CL      None   \n",
       "9        NA          US      US-CA   Pine Valley     00CN      None   \n",
       "\n",
       "  local_code                              coordinates  \n",
       "0        00A       -74.93360137939453, 40.07080078125  \n",
       "1       00AA                   -101.473911, 38.704022  \n",
       "2       00AK              -151.695999146, 59.94919968  \n",
       "3       00AL    -86.77030181884766, 34.86479949951172  \n",
       "4       None                      -91.254898, 35.6087  \n",
       "5       00AS                  -97.8180194, 34.9428028  \n",
       "6       00AZ  -112.16500091552734, 34.305599212646484  \n",
       "7       00CA       -116.888000488, 35.350498199499995  \n",
       "8       00CL                   -121.763427, 39.427188  \n",
       "9       00CN                 -116.4597417, 32.7273736  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports = load_csv(spark=spark, path='data/airport-codes_csv.csv')\n",
    "print_data(airports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>529</td>\n",
       "      <td>ANGUILLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>518</td>\n",
       "      <td>ANTIGUA-BARBUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>687</td>\n",
       "      <td>ARGENTINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151</td>\n",
       "      <td>ARMENIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code                                               name\n",
       "0  582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1  236                                        AFGHANISTAN\n",
       "2  101                                            ALBANIA\n",
       "3  316                                            ALGERIA\n",
       "4  102                                            ANDORRA\n",
       "5  324                                             ANGOLA\n",
       "6  529                                           ANGUILLA\n",
       "7  518                                    ANTIGUA-BARBUDA\n",
       "8  687                                          ARGENTINA\n",
       "9  151                                            ARMENIA"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = load_csv(spark, 'data/countries.csv')\n",
    "print_data(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 1999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>5.7879999999999985</td>\n",
       "      <td>3.6239999999999997</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>10.644</td>\n",
       "      <td>1.2830000000000001</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>14.050999999999998</td>\n",
       "      <td>1.347</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>16.082</td>\n",
       "      <td>1.396</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1744-08-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068            1.7369999999999999  Århus   \n",
       "1  1743-12-01                None                          None  Århus   \n",
       "2  1744-01-01                None                          None  Århus   \n",
       "3  1744-02-01                None                          None  Århus   \n",
       "4  1744-03-01                None                          None  Århus   \n",
       "5  1744-04-01  5.7879999999999985            3.6239999999999997  Århus   \n",
       "6  1744-05-01              10.644            1.2830000000000001  Århus   \n",
       "7  1744-06-01  14.050999999999998                         1.347  Århus   \n",
       "8  1744-07-01              16.082                         1.396  Århus   \n",
       "9  1744-08-01                None                          None  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  \n",
       "5  Denmark   57.05N    10.33E  \n",
       "6  Denmark   57.05N    10.33E  \n",
       "7  Denmark   57.05N    10.33E  \n",
       "8  Denmark   57.05N    10.33E  \n",
       "9  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = load_csv(spark, 'data/GlobalLandTemperaturesByCitySample.csv')\n",
    "print_data(temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 3096313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5748522.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20579.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.498180e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5748523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20586.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497969e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5748524.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20586.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497975e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5748525.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497325e+10</td>\n",
       "      <td>00028</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5748526.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.501355e+10</td>\n",
       "      <td>00002</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "5  5748522.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "6  5748523.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "7  5748524.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "8  5748525.0  2016.0     4.0   245.0   464.0     HOU  20574.0      1.0   \n",
       "9  5748526.0  2016.0     4.0   245.0   464.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate  ...  entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      CA  20582.0  ...     None        M   1976.0  10292016      F   None   \n",
       "1      NV  20591.0  ...     None        M   1984.0  10292016      F   None   \n",
       "2      WA  20582.0  ...     None        M   1987.0  10292016      M   None   \n",
       "3      WA  20588.0  ...     None        M   1987.0  10292016      F   None   \n",
       "4      WA  20588.0  ...     None        M   1988.0  10292016      M   None   \n",
       "5      HI  20579.0  ...     None        M   1959.0  10292016      M   None   \n",
       "6      HI  20586.0  ...     None        M   1950.0  10292016      F   None   \n",
       "7      HI  20586.0  ...     None        M   1975.0  10292016      F   None   \n",
       "8      FL  20581.0  ...     None        M   1989.0  10292016      M   None   \n",
       "9      CA  20581.0  ...     None        M   1990.0  10292016      F   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0      QF  9.495387e+10  00011       B1  \n",
       "1      VA  9.495562e+10  00007       B1  \n",
       "2      DL  9.495641e+10  00040       B1  \n",
       "3      DL  9.495645e+10  00040       B1  \n",
       "4      DL  9.495639e+10  00040       B1  \n",
       "5      NZ  9.498180e+10  00010       B2  \n",
       "6      NZ  9.497969e+10  00010       B2  \n",
       "7      NZ  9.497975e+10  00010       B2  \n",
       "8      NZ  9.497325e+10  00028       B2  \n",
       "9      NZ  9.501355e+10  00002       B2  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration = load_parquet(spark, 'data/sas_data')\n",
    "print_data(immigration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Clean the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean demographic dataset\n",
    "\n",
    "* Cast numeric data to integer or float based on the meaning.\n",
    "* Fill 0 in numeric columns if data is lost.\n",
    "* Rename the columns to snake_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 2891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>city</th>\n",
       "      <th>count</th>\n",
       "      <th>female_population</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>male_population</th>\n",
       "      <th>median_age</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>race</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>total_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.56</td>\n",
       "      <td>Wichita</td>\n",
       "      <td>8791</td>\n",
       "      <td>197601</td>\n",
       "      <td>40270</td>\n",
       "      <td>192354</td>\n",
       "      <td>34.599998</td>\n",
       "      <td>23978</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>KS</td>\n",
       "      <td>389955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.67</td>\n",
       "      <td>Allen</td>\n",
       "      <td>22304</td>\n",
       "      <td>59581</td>\n",
       "      <td>19652</td>\n",
       "      <td>60626</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>5691</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "      <td>120207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.74</td>\n",
       "      <td>Danbury</td>\n",
       "      <td>8454</td>\n",
       "      <td>41227</td>\n",
       "      <td>25675</td>\n",
       "      <td>43435</td>\n",
       "      <td>37.299999</td>\n",
       "      <td>3752</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>CT</td>\n",
       "      <td>84662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.39</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>67526</td>\n",
       "      <td>340365</td>\n",
       "      <td>88193</td>\n",
       "      <td>314231</td>\n",
       "      <td>34.099998</td>\n",
       "      <td>27942</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>TN</td>\n",
       "      <td>654596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.70</td>\n",
       "      <td>Stamford</td>\n",
       "      <td>11013</td>\n",
       "      <td>63936</td>\n",
       "      <td>44003</td>\n",
       "      <td>64941</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>2269</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>CT</td>\n",
       "      <td>128877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>335559</td>\n",
       "      <td>186829</td>\n",
       "      <td>0</td>\n",
       "      <td>155408</td>\n",
       "      <td>41.400002</td>\n",
       "      <td>0</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>342237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.28</td>\n",
       "      <td>Provo</td>\n",
       "      <td>108471</td>\n",
       "      <td>59027</td>\n",
       "      <td>10925</td>\n",
       "      <td>56231</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>2177</td>\n",
       "      <td>White</td>\n",
       "      <td>Utah</td>\n",
       "      <td>UT</td>\n",
       "      <td>115258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.13</td>\n",
       "      <td>San Marcos</td>\n",
       "      <td>4447</td>\n",
       "      <td>47688</td>\n",
       "      <td>21558</td>\n",
       "      <td>45246</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>5189</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>92934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.27</td>\n",
       "      <td>Escondido</td>\n",
       "      <td>3151</td>\n",
       "      <td>74907</td>\n",
       "      <td>46298</td>\n",
       "      <td>76551</td>\n",
       "      <td>33.299999</td>\n",
       "      <td>8110</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>151458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>76349</td>\n",
       "      <td>42265</td>\n",
       "      <td>0</td>\n",
       "      <td>34743</td>\n",
       "      <td>40.400002</td>\n",
       "      <td>0</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>77008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_household_size        city   count  female_population  \\\n",
       "0                    2.56     Wichita    8791             197601   \n",
       "1                    2.67       Allen   22304              59581   \n",
       "2                    2.74     Danbury    8454              41227   \n",
       "3                    2.39   Nashville   67526             340365   \n",
       "4                    2.70    Stamford   11013              63936   \n",
       "5                    0.00    San Juan  335559             186829   \n",
       "6                    3.28       Provo  108471              59027   \n",
       "7                    3.13  San Marcos    4447              47688   \n",
       "8                    3.27   Escondido    3151              74907   \n",
       "9                    0.00      Caguas   76349              42265   \n",
       "\n",
       "   foreign_born  male_population  median_age  number_of_veterans  \\\n",
       "0         40270           192354   34.599998               23978   \n",
       "1         19652            60626   33.500000                5691   \n",
       "2         25675            43435   37.299999                3752   \n",
       "3         88193           314231   34.099998               27942   \n",
       "4         44003            64941   35.400002                2269   \n",
       "5             0           155408   41.400002                   0   \n",
       "6         10925            56231   23.600000                2177   \n",
       "7         21558            45246   35.400002                5189   \n",
       "8         46298            76551   33.299999                8110   \n",
       "9             0            34743   40.400002                   0   \n",
       "\n",
       "                                race         state state_code  \\\n",
       "0  American Indian and Alaska Native        Kansas         KS   \n",
       "1          Black or African-American  Pennsylvania         PA   \n",
       "2          Black or African-American   Connecticut         CT   \n",
       "3                 Hispanic or Latino     Tennessee         TN   \n",
       "4                              Asian   Connecticut         CT   \n",
       "5                 Hispanic or Latino   Puerto Rico         PR   \n",
       "6                              White          Utah         UT   \n",
       "7          Black or African-American    California         CA   \n",
       "8  American Indian and Alaska Native    California         CA   \n",
       "9                 Hispanic or Latino   Puerto Rico         PR   \n",
       "\n",
       "   total_population  \n",
       "0            389955  \n",
       "1            120207  \n",
       "2             84662  \n",
       "3            654596  \n",
       "4            128877  \n",
       "5            342237  \n",
       "6            115258  \n",
       "7             92934  \n",
       "8            151458  \n",
       "9             77008  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics = clean_demographics(demographics)\n",
    "print_data(demographics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean airport dataset\n",
    "\n",
    "* Remove the data row with null value in the columns to be FK.\n",
    "* Cast elevation_ft with float data type.\n",
    "* Substr iso_region to get regin code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 14383\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>None</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>None</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>-112.16500091552734, 34.305599212646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00CA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldstone /Gts/ Airport</td>\n",
       "      <td>3038.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "      <td>Barstow</td>\n",
       "      <td>00CA</td>\n",
       "      <td>None</td>\n",
       "      <td>00CA</td>\n",
       "      <td>-116.888000488, 35.350498199499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00CL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Williams Ag Airport</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>00CL</td>\n",
       "      <td>None</td>\n",
       "      <td>00CL</td>\n",
       "      <td>-121.763427, 39.427188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Grass Patch Airport</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>FL</td>\n",
       "      <td>Bushnell</td>\n",
       "      <td>00FA</td>\n",
       "      <td>None</td>\n",
       "      <td>00FA</td>\n",
       "      <td>-82.21900177001953, 28.64550018310547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00FL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>River Oak Airport</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>FL</td>\n",
       "      <td>Okeechobee</td>\n",
       "      <td>00FL</td>\n",
       "      <td>None</td>\n",
       "      <td>00FL</td>\n",
       "      <td>-80.96920013427734, 27.230899810791016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00GA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lt World Airport</td>\n",
       "      <td>700.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>GA</td>\n",
       "      <td>Lithonia</td>\n",
       "      <td>00GA</td>\n",
       "      <td>None</td>\n",
       "      <td>00GA</td>\n",
       "      <td>-84.06829833984375, 33.76750183105469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                     name  elevation_ft continent  \\\n",
       "0  00AA  small_airport     Aero B Ranch Airport        3435.0        NA   \n",
       "1  00AK  small_airport             Lowell Field         450.0        NA   \n",
       "2  00AL  small_airport             Epps Airpark         820.0        NA   \n",
       "3  00AS  small_airport           Fulton Airport        1100.0        NA   \n",
       "4  00AZ  small_airport           Cordes Airport        3810.0        NA   \n",
       "5  00CA  small_airport  Goldstone /Gts/ Airport        3038.0        NA   \n",
       "6  00CL  small_airport      Williams Ag Airport          87.0        NA   \n",
       "7  00FA  small_airport      Grass Patch Airport          53.0        NA   \n",
       "8  00FL  small_airport        River Oak Airport          35.0        NA   \n",
       "9  00GA  small_airport         Lt World Airport         700.0        NA   \n",
       "\n",
       "  iso_country iso_region  municipality gps_code iata_code local_code  \\\n",
       "0          US         KS         Leoti     00AA      None       00AA   \n",
       "1          US         AK  Anchor Point     00AK      None       00AK   \n",
       "2          US         AL       Harvest     00AL      None       00AL   \n",
       "3          US         OK          Alex     00AS      None       00AS   \n",
       "4          US         AZ        Cordes     00AZ      None       00AZ   \n",
       "5          US         CA       Barstow     00CA      None       00CA   \n",
       "6          US         CA         Biggs     00CL      None       00CL   \n",
       "7          US         FL      Bushnell     00FA      None       00FA   \n",
       "8          US         FL    Okeechobee     00FL      None       00FL   \n",
       "9          US         GA      Lithonia     00GA      None       00GA   \n",
       "\n",
       "                               coordinates  \n",
       "0                   -101.473911, 38.704022  \n",
       "1              -151.695999146, 59.94919968  \n",
       "2    -86.77030181884766, 34.86479949951172  \n",
       "3                  -97.8180194, 34.9428028  \n",
       "4  -112.16500091552734, 34.305599212646484  \n",
       "5       -116.888000488, 35.350498199499995  \n",
       "6                   -121.763427, 39.427188  \n",
       "7    -82.21900177001953, 28.64550018310547  \n",
       "8   -80.96920013427734, 27.230899810791016  \n",
       "9    -84.06829833984375, 33.76750183105469  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports = clean_airports(airports)\n",
    "print_data(airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean countries dataset\n",
    "\n",
    "* change the name to match the names in demographics for further operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>529</td>\n",
       "      <td>ANGUILLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>518</td>\n",
       "      <td>ANTIGUA-BARBUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>687</td>\n",
       "      <td>ARGENTINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151</td>\n",
       "      <td>ARMENIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code             name\n",
       "0   582           MEXICO\n",
       "1   236      AFGHANISTAN\n",
       "2   101          ALBANIA\n",
       "3   316          ALGERIA\n",
       "4   102          ANDORRA\n",
       "5   324           ANGOLA\n",
       "6   529         ANGUILLA\n",
       "7   518  ANTIGUA-BARBUDA\n",
       "8   687        ARGENTINA\n",
       "9   151          ARMENIA"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = clean_countries(countries)\n",
    "print_data(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean temperature dataset\n",
    "\n",
    "* Remove the data row if AverageTemperature is lost.\n",
    "* Rename the column name to snake_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 1927\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>5.7879999999999985</td>\n",
       "      <td>3.6239999999999997</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>10.644</td>\n",
       "      <td>1.2830000000000001</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>14.050999999999998</td>\n",
       "      <td>1.347</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>16.082</td>\n",
       "      <td>1.396</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1744-09-01</td>\n",
       "      <td>12.780999999999999</td>\n",
       "      <td>1.454</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1744-10-01</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1.63</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1744-11-01</td>\n",
       "      <td>4.638999999999999</td>\n",
       "      <td>1.3019999999999998</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1744-12-01</td>\n",
       "      <td>0.12199999999999987</td>\n",
       "      <td>1.756</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1745-01-01</td>\n",
       "      <td>-1.3330000000000002</td>\n",
       "      <td>1.642</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  average_temperature average_temperature_uncertainty   city  \\\n",
       "0  1743-11-01                6.068              1.7369999999999999  Århus   \n",
       "1  1744-04-01   5.7879999999999985              3.6239999999999997  Århus   \n",
       "2  1744-05-01               10.644              1.2830000000000001  Århus   \n",
       "3  1744-06-01   14.050999999999998                           1.347  Århus   \n",
       "4  1744-07-01               16.082                           1.396  Århus   \n",
       "5  1744-09-01   12.780999999999999                           1.454  Århus   \n",
       "6  1744-10-01                 7.95                            1.63  Århus   \n",
       "7  1744-11-01    4.638999999999999              1.3019999999999998  Århus   \n",
       "8  1744-12-01  0.12199999999999987                           1.756  Århus   \n",
       "9  1745-01-01  -1.3330000000000002                           1.642  Århus   \n",
       "\n",
       "   country latitude longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  \n",
       "5  Denmark   57.05N    10.33E  \n",
       "6  Denmark   57.05N    10.33E  \n",
       "7  Denmark   57.05N    10.33E  \n",
       "8  Denmark   57.05N    10.33E  \n",
       "9  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = clean_temperature(temperature)\n",
    "print_data(temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean immigration dataset\n",
    "\n",
    "* Drop unnucessary columns.\n",
    "* Cast numeric data to integer.\n",
    "* Cast date data to date string, %Y-%m-%d.\n",
    "* Remove the row if the data in any of fk column is lost, 'i94cit', 'i94port', 'i94addr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 2943721\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>QF</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>VA</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>20160430</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>DL</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>20160430</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5748522</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>464</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>20160430</td>\n",
       "      <td>M</td>\n",
       "      <td>NZ</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5748523</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>464</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>NZ</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5748524</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>464</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>NZ</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5748525</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>464</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>20160430</td>\n",
       "      <td>M</td>\n",
       "      <td>NZ</td>\n",
       "      <td>00028</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5748526</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>464</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>NZ</td>\n",
       "      <td>00002</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cicid  i94yr  i94mon  i94cit  i94res i94port     arrdate  i94mode  \\\n",
       "0  5748517   2016       4     245     438     LOS  2016-04-30        1   \n",
       "1  5748518   2016       4     245     438     LOS  2016-04-30        1   \n",
       "2  5748519   2016       4     245     438     LOS  2016-04-30        1   \n",
       "3  5748520   2016       4     245     438     LOS  2016-04-30        1   \n",
       "4  5748521   2016       4     245     438     LOS  2016-04-30        1   \n",
       "5  5748522   2016       4     245     464     HHW  2016-04-30        1   \n",
       "6  5748523   2016       4     245     464     HHW  2016-04-30        1   \n",
       "7  5748524   2016       4     245     464     HHW  2016-04-30        1   \n",
       "8  5748525   2016       4     245     464     HOU  2016-04-30        1   \n",
       "9  5748526   2016       4     245     464     LOS  2016-04-30        1   \n",
       "\n",
       "  i94addr     depdate  i94bir  i94visa  dtadfile gender airline  fltno  \\\n",
       "0      CA  2016-05-08      40        1  20160430      F      QF  00011   \n",
       "1      NV  2016-05-17      32        1  20160430      F      VA  00007   \n",
       "2      WA  2016-05-08      29        1  20160430      M      DL  00040   \n",
       "3      WA  2016-05-14      29        1  20160430      F      DL  00040   \n",
       "4      WA  2016-05-14      28        1  20160430      M      DL  00040   \n",
       "5      HI  2016-05-05      57        2  20160430      M      NZ  00010   \n",
       "6      HI  2016-05-12      66        2  20160430      F      NZ  00010   \n",
       "7      HI  2016-05-12      41        2  20160430      F      NZ  00010   \n",
       "8      FL  2016-05-07      27        2  20160430      M      NZ  00028   \n",
       "9      CA  2016-05-07      26        2  20160430      F      NZ  00002   \n",
       "\n",
       "  visatype  \n",
       "0       B1  \n",
       "1       B1  \n",
       "2       B1  \n",
       "3       B1  \n",
       "4       B1  \n",
       "5       B2  \n",
       "6       B2  \n",
       "7       B2  \n",
       "8       B2  \n",
       "9       B2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration = clean_immigration(immigration)\n",
    "print_data(immigration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1 Conceptual Data Model\n",
    "\n",
    "The data model is implemented by following the **star schema** with a fact table and several dimension tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Dimension Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dim_demographics**\n",
    "\n",
    "This table is the aggregrated table of demographics at state level. The population columns and number of veterans and foreign-born were applied to `first` function when grouping by `city` because there are repeatedly in different row of the same cities. And the `sum` function were used to get the total number of these population columns and number of veterans and foreign-born. It's obviously to apply `avg` function to the fields of median age and average household size when groupping by the state. Finally, race information were extract respevitvely by `pivo`.\n",
    "\n",
    "\n",
    "| Field Name|\n",
    "| :--- |\n",
    "| state_code (FK) |\n",
    "| satte |\n",
    "| median_age |\n",
    "| male_population |\n",
    "| female_population |\n",
    "| total_population |\n",
    "| number_of_veterans |\n",
    "| average_household_size |\n",
    "| foreign_born |\n",
    "| hispanic_or_latino |\n",
    "| american_indian_and_alaska_native |\n",
    "| black_or_african_american |\n",
    "| white |\n",
    "| asian |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dim_airports**\n",
    "\n",
    "This table was just cleaned. No more process on it.\n",
    "\n",
    "| Field Name|\n",
    "| :--- |\n",
    "| local_code (FK) |\n",
    "| ident |\n",
    "| type |\n",
    "| name |\n",
    "| elevation_ft |\n",
    "| continent |\n",
    "| iso_country |\n",
    "| iso_region |\n",
    "| municipality |\n",
    "| gps_code |\n",
    "| iata_code |\n",
    "| coordinates |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dim_countries**\n",
    "\n",
    "The information of countries was first extract from `I94_SAS_Labels_Descriptions.SAS` and store the data in csv file. This table contains countries dataset and temperature dataset. a lowercase country name was added to both countries and temperature dataset for joining purpose and it's eventually dropped to aviod the duplicate in dimension table.\n",
    "\n",
    "| Field Name|\n",
    "| :--- |\n",
    "| code (FK) |\n",
    "| name |\n",
    "| average_temperature |\n",
    "| latitude |\n",
    "| longitude |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Fact Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fact_immigration**\n",
    "\n",
    "This table was firstly cleaned and dropped some unnecessary columns and then I split the arrive date into year, month and day for partitioning purpose. Besides, the immigration dataset is joined with dimension tables and processed countries dataset to remove those data row which are not matched against dimension tables. \n",
    "\n",
    "| Field Name| FK |\n",
    "| :--- | :--- |\n",
    "| cicid | |\n",
    "| i94yr | |\n",
    "| i94mon | |\n",
    "| i94cit | dim_countries |\n",
    "| i94res | |\n",
    "| i94port | dim_airports |\n",
    "| arrdate | |\n",
    "| i94mode | |\n",
    "| i94addr | dim_demographics |\n",
    "| depdate | |\n",
    "| i94bir | |\n",
    "| i94visa | |\n",
    "| dtadfile | |\n",
    "| gender | |\n",
    "| airline | |\n",
    "| fltno | |\n",
    "| visatype | |\n",
    "| arr_year | |\n",
    "| arr_month | |\n",
    "| arr_day | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "_List the steps necessary to pipeline the data into the chosen data model_\n",
    "\n",
    "The basic steps of pipeline is **loading**, **cleaning**, **transforming**, **modeling** and **quality checking**.\n",
    "\n",
    "Apach Spark is main tool to build the methods to work arond the data pipeline. \n",
    "\n",
    "The relationship amoung these steps is shown as below dag.\n",
    "\n",
    "![capstone dag](capstone-dag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Transform Data to Match Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>hispanic_or_latino</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>asian</th>\n",
       "      <th>male_population</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>total_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>black_or_african_american</th>\n",
       "      <th>median_age</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>american_indian_and_alaska_native</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>MS</td>\n",
       "      <td>7264</td>\n",
       "      <td>4861</td>\n",
       "      <td>2587</td>\n",
       "      <td>112147</td>\n",
       "      <td>2.595000</td>\n",
       "      <td>242683</td>\n",
       "      <td>130536</td>\n",
       "      <td>167366</td>\n",
       "      <td>33.400000</td>\n",
       "      <td>14792</td>\n",
       "      <td>323</td>\n",
       "      <td>71645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Utah</td>\n",
       "      <td>UT</td>\n",
       "      <td>201695</td>\n",
       "      <td>132819</td>\n",
       "      <td>48801</td>\n",
       "      <td>530818</td>\n",
       "      <td>3.175000</td>\n",
       "      <td>1050591</td>\n",
       "      <td>519773</td>\n",
       "      <td>21893</td>\n",
       "      <td>30.980000</td>\n",
       "      <td>39671</td>\n",
       "      <td>18746</td>\n",
       "      <td>889798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>SD</td>\n",
       "      <td>12359</td>\n",
       "      <td>15309</td>\n",
       "      <td>6859</td>\n",
       "      <td>122718</td>\n",
       "      <td>2.345000</td>\n",
       "      <td>245098</td>\n",
       "      <td>122380</td>\n",
       "      <td>13121</td>\n",
       "      <td>37.049999</td>\n",
       "      <td>16087</td>\n",
       "      <td>13782</td>\n",
       "      <td>213281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>KY</td>\n",
       "      <td>50478</td>\n",
       "      <td>66488</td>\n",
       "      <td>32667</td>\n",
       "      <td>452483</td>\n",
       "      <td>2.395000</td>\n",
       "      <td>929877</td>\n",
       "      <td>477394</td>\n",
       "      <td>202749</td>\n",
       "      <td>35.950001</td>\n",
       "      <td>56025</td>\n",
       "      <td>7772</td>\n",
       "      <td>705790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>9856464</td>\n",
       "      <td>7448257</td>\n",
       "      <td>4543730</td>\n",
       "      <td>12278281</td>\n",
       "      <td>3.100949</td>\n",
       "      <td>24822460</td>\n",
       "      <td>12544179</td>\n",
       "      <td>2047009</td>\n",
       "      <td>36.182482</td>\n",
       "      <td>928270</td>\n",
       "      <td>401386</td>\n",
       "      <td>14905129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>NE</td>\n",
       "      <td>83812</td>\n",
       "      <td>71221</td>\n",
       "      <td>34243</td>\n",
       "      <td>357333</td>\n",
       "      <td>2.435000</td>\n",
       "      <td>721233</td>\n",
       "      <td>363900</td>\n",
       "      <td>80668</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>39197</td>\n",
       "      <td>10599</td>\n",
       "      <td>600094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>NH</td>\n",
       "      <td>22473</td>\n",
       "      <td>27199</td>\n",
       "      <td>13989</td>\n",
       "      <td>97771</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>198198</td>\n",
       "      <td>100427</td>\n",
       "      <td>11043</td>\n",
       "      <td>37.799999</td>\n",
       "      <td>11005</td>\n",
       "      <td>1213</td>\n",
       "      <td>174085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>DE</td>\n",
       "      <td>5516</td>\n",
       "      <td>3336</td>\n",
       "      <td>1193</td>\n",
       "      <td>32680</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>71957</td>\n",
       "      <td>39277</td>\n",
       "      <td>44182</td>\n",
       "      <td>36.400002</td>\n",
       "      <td>3063</td>\n",
       "      <td>414</td>\n",
       "      <td>23743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>103229</td>\n",
       "      <td>215873</td>\n",
       "      <td>151544</td>\n",
       "      <td>702157</td>\n",
       "      <td>2.500909</td>\n",
       "      <td>1422403</td>\n",
       "      <td>720246</td>\n",
       "      <td>216731</td>\n",
       "      <td>35.618182</td>\n",
       "      <td>64894</td>\n",
       "      <td>25242</td>\n",
       "      <td>1050239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>NC</td>\n",
       "      <td>354409</td>\n",
       "      <td>379327</td>\n",
       "      <td>178740</td>\n",
       "      <td>1466105</td>\n",
       "      <td>2.475000</td>\n",
       "      <td>3060199</td>\n",
       "      <td>1594094</td>\n",
       "      <td>1029446</td>\n",
       "      <td>33.785715</td>\n",
       "      <td>166146</td>\n",
       "      <td>35209</td>\n",
       "      <td>1790136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            state state_code  hispanic_or_latino  foreign_born    asian  \\\n",
       "0     Mississippi         MS                7264          4861     2587   \n",
       "1            Utah         UT              201695        132819    48801   \n",
       "2    South Dakota         SD               12359         15309     6859   \n",
       "3        Kentucky         KY               50478         66488    32667   \n",
       "4      California         CA             9856464       7448257  4543730   \n",
       "5        Nebraska         NE               83812         71221    34243   \n",
       "6   New Hampshire         NH               22473         27199    13989   \n",
       "7        Delaware         DE                5516          3336     1193   \n",
       "8       Minnesota         MN              103229        215873   151544   \n",
       "9  North Carolina         NC              354409        379327   178740   \n",
       "\n",
       "   male_population  average_household_size  total_population  \\\n",
       "0           112147                2.595000            242683   \n",
       "1           530818                3.175000           1050591   \n",
       "2           122718                2.345000            245098   \n",
       "3           452483                2.395000            929877   \n",
       "4         12278281                3.100949          24822460   \n",
       "5           357333                2.435000            721233   \n",
       "6            97771                2.430000            198198   \n",
       "7            32680                2.450000             71957   \n",
       "8           702157                2.500909           1422403   \n",
       "9          1466105                2.475000           3060199   \n",
       "\n",
       "   female_population  black_or_african_american  median_age  \\\n",
       "0             130536                     167366   33.400000   \n",
       "1             519773                      21893   30.980000   \n",
       "2             122380                      13121   37.049999   \n",
       "3             477394                     202749   35.950001   \n",
       "4           12544179                    2047009   36.182482   \n",
       "5             363900                      80668   33.250000   \n",
       "6             100427                      11043   37.799999   \n",
       "7              39277                      44182   36.400002   \n",
       "8             720246                     216731   35.618182   \n",
       "9            1594094                    1029446   33.785715   \n",
       "\n",
       "   number_of_veterans  american_indian_and_alaska_native     white  \n",
       "0               14792                                323     71645  \n",
       "1               39671                              18746    889798  \n",
       "2               16087                              13782    213281  \n",
       "3               56025                               7772    705790  \n",
       "4              928270                             401386  14905129  \n",
       "5               39197                              10599    600094  \n",
       "6               11005                               1213    174085  \n",
       "7                3063                                414     23743  \n",
       "8               64894                              25242   1050239  \n",
       "9              166146                              35209   1790136  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics = transform_demographics(demographics)\n",
    "print_data(demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>lower_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "      <td>algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "      <td>andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "      <td>angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>529</td>\n",
       "      <td>ANGUILLA</td>\n",
       "      <td>anguilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>518</td>\n",
       "      <td>ANTIGUA-BARBUDA</td>\n",
       "      <td>antigua-barbuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>687</td>\n",
       "      <td>ARGENTINA</td>\n",
       "      <td>argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151</td>\n",
       "      <td>ARMENIA</td>\n",
       "      <td>armenia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code             name       lower_name\n",
       "0   582           MEXICO           mexico\n",
       "1   236      AFGHANISTAN      afghanistan\n",
       "2   101          ALBANIA          albania\n",
       "3   316          ALGERIA          algeria\n",
       "4   102          ANDORRA          andorra\n",
       "5   324           ANGOLA           angola\n",
       "6   529         ANGUILLA         anguilla\n",
       "7   518  ANTIGUA-BARBUDA  antigua-barbuda\n",
       "8   687        ARGENTINA        argentina\n",
       "9   151          ARMENIA          armenia"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = transform_countries(countries)\n",
    "print_data(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lower_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>7.44682</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>denmark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  average_temperature latitude longitude lower_name\n",
       "0  Denmark              7.44682   57.05N    10.33E    denmark"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = transform_temperature(temperature)\n",
    "print_data(temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count: 2943721\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>arr_year</th>\n",
       "      <th>arr_month</th>\n",
       "      <th>arr_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>QF</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>VA</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>20160430</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>DL</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>20160430</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5748522</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>464</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>20160430</td>\n",
       "      <td>M</td>\n",
       "      <td>NZ</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5748523</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>464</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>NZ</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5748524</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>464</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>NZ</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5748525</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>464</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>20160430</td>\n",
       "      <td>M</td>\n",
       "      <td>NZ</td>\n",
       "      <td>00028</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5748526</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>464</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>20160430</td>\n",
       "      <td>F</td>\n",
       "      <td>NZ</td>\n",
       "      <td>00002</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cicid  i94yr  i94mon  i94cit  i94res i94port     arrdate  i94mode  \\\n",
       "0  5748517   2016       4     245     438     LOS  2016-04-30        1   \n",
       "1  5748518   2016       4     245     438     LOS  2016-04-30        1   \n",
       "2  5748519   2016       4     245     438     LOS  2016-04-30        1   \n",
       "3  5748520   2016       4     245     438     LOS  2016-04-30        1   \n",
       "4  5748521   2016       4     245     438     LOS  2016-04-30        1   \n",
       "5  5748522   2016       4     245     464     HHW  2016-04-30        1   \n",
       "6  5748523   2016       4     245     464     HHW  2016-04-30        1   \n",
       "7  5748524   2016       4     245     464     HHW  2016-04-30        1   \n",
       "8  5748525   2016       4     245     464     HOU  2016-04-30        1   \n",
       "9  5748526   2016       4     245     464     LOS  2016-04-30        1   \n",
       "\n",
       "  i94addr     depdate  i94bir  i94visa  dtadfile gender airline  fltno  \\\n",
       "0      CA  2016-05-08      40        1  20160430      F      QF  00011   \n",
       "1      NV  2016-05-17      32        1  20160430      F      VA  00007   \n",
       "2      WA  2016-05-08      29        1  20160430      M      DL  00040   \n",
       "3      WA  2016-05-14      29        1  20160430      F      DL  00040   \n",
       "4      WA  2016-05-14      28        1  20160430      M      DL  00040   \n",
       "5      HI  2016-05-05      57        2  20160430      M      NZ  00010   \n",
       "6      HI  2016-05-12      66        2  20160430      F      NZ  00010   \n",
       "7      HI  2016-05-12      41        2  20160430      F      NZ  00010   \n",
       "8      FL  2016-05-07      27        2  20160430      M      NZ  00028   \n",
       "9      CA  2016-05-07      26        2  20160430      F      NZ  00002   \n",
       "\n",
       "  visatype arr_year arr_month arr_day  \n",
       "0       B1     2016        04      30  \n",
       "1       B1     2016        04      30  \n",
       "2       B1     2016        04      30  \n",
       "3       B1     2016        04      30  \n",
       "4       B1     2016        04      30  \n",
       "5       B2     2016        04      30  \n",
       "6       B2     2016        04      30  \n",
       "7       B2     2016        04      30  \n",
       "8       B2     2016        04      30  \n",
       "9       B2     2016        04      30  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration = transform_immigration(immigration)\n",
    "print_data(immigration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Model Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimension Tables**\n",
    "\n",
    "Dimension demographics and dimension airports are modeled directly after cleaning and transforming. About the dimension countries is combined countries dataset and temperature dataset. They are joined by `lower_name` as the key and the duplicated columns were removed before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dim_demographics(demographics, 'models/dim_demographics.parquet')\n",
    "model_dim_airports(airports, 'models/dim_airports.parquet')\n",
    "model_dim_countries(countries, temperature, 'models/dim_countries.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fact Table**\n",
    "\n",
    "The fact immigration table is first joined with dimension tables and processed countries to clean the unnecessary data rows. And then it's modeling wiht the partition of arrived year, month and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fact_immigration(immigration, demographics, airports, countries, 'models/fact_immigration.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Data Quality Checks\n",
    "\n",
    "_**Explain the data quality checks you'll perform to ensure the pipeline ran as expected**_\n",
    "\n",
    "The data quality check focuses on follows:\n",
    "\n",
    "1. Ensure the fact table and all the dimension tables have the data by counting the data row.\n",
    "\n",
    "2. Ensure the integrity of fact table with all the dimension tables by joining the dimension tables wiht `left_anti` strategy and count the joined tables.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Existence Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from parquet files\n",
    "dim_demographics = load_parquet(spark, 'models/dim_demographics.parquet')\n",
    "dim_airports = load_parquet(spark, 'models/dim_airports.parquet')\n",
    "dim_countries = load_parquet(spark, 'models/dim_countries.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_existence(dim_demographics)\n",
    "check_existence(dim_airports)\n",
    "check_existence(dim_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_immigration = load_parquet(spark, 'models/fact_immigration.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_existence(fact_immigration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Integrity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check fact table integrity and the order of arguments matters.\n",
    "check_fact_table_integrity(\n",
    "    fact_immigration,\n",
    "    dim_demographics,\n",
    "    dim_airports,\n",
    "    dim_countries\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Data dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fact Table, Immigration**\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| CICID | Record ID |\n",
    "| I94YR | 4 digit year |\n",
    "| I94MON | Numeric month |\n",
    "| I94CIT | Contry of citizenship |\n",
    "| I94RES | Country of residence |\n",
    "| I94PORT | Airport of addmittance into the USA |\n",
    "| ARRDATE | Arrival date in the USA |\n",
    "| I94MODE | Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported) |\n",
    "| I94ADDR | State of arrival |\n",
    "| DEPDATE | Departure date |\n",
    "| I94BIR | Age of the visitor |\n",
    "| I94VISA | Visa codes: (1 = Business; 2 = Pleasure; 3 = Student) |\n",
    "| DTADFILE | Character date field |\n",
    "| GENDER | Gender of the visitor |\n",
    "| VISAPOST | Department of State where where Visa was issued |\n",
    "| FLTNO | Flight number of Airline used to arrive in U.S. |\n",
    "| VISATYPE | Class of admission legally admitting the non-immigrant to temporarily stay in U.S. |\n",
    "| arr_year | arrival year, for data partitioning |\n",
    "| arr_month | arrival month, for data partitioning |\n",
    "| arr_day | arrival day, for data partitioning |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimension Table, Demographics**\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| STATE_CODE | Two-letter code of the state |\n",
    "| STATE | Name of the state |\n",
    "| MEDIAN_AGE | Median age in the state (estimation) |\n",
    "| AVERAGE_HOUSEHOLD_SIZE | Average number of people in a household in the state (estimation) |\n",
    "| TOTAL_POPULATION | Total population of the state |\n",
    "| FEMALE_POPULATION | Femal population of the state |\n",
    "| MALE_POPULATION | Male population of the state |\n",
    "| NUMBER_OF_VETERANS | Population of veteran citizens |\n",
    "| BLACK_OR_AFRICAN_AMERICAN | Population belonging to this ethnic group |\n",
    "| HISPANIC_OR_LATINO | Population belonging to this ethnic group |\n",
    "| ASIAN | Population belonging to this ethnic group |\n",
    "| AMERICAN_INDIAN_AND_ALASKA_NATIVE | Population belonging to this ethnic group |\n",
    "| WHITE | Population belonging to this ethnic group |\n",
    "| FOREIGN_BORN | Population of citizens born outside of US |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimension Table, Airports**\n",
    "\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| IDENT | Identification code |\n",
    "| TYPE | Type of the Airport |\n",
    "| NAME | Name of the Airport |\n",
    "| ELEVATION_FT | Elevation above the sea level in feet |\n",
    "| CONTINENT | Continent code |\n",
    "| ISO_COUNTRY | Country code according to ISO |\n",
    "| ISO_REGION | Region code according to ISO, 'US' is removed |\n",
    "| MUNICIPALITY | Mucipality where the airport is located |\n",
    "| GPS_CODE | GPS code |\n",
    "| IATA_CODE | Code of the airport assigned by International Air Transport Association |\n",
    "| LOCAL_CODE | Local code of the airport |\n",
    "| COORDINATES | GPS coordinates - longitude and latitude |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimension Table, Countries**\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| CODE | Country Code |\n",
    "| NAME | Country Name |\n",
    "| TEMPERATURE | Average temperature of the country between 1743 and 2013 |\n",
    "| LATITUDE | GPS Latitude |\n",
    "| LONGITUDE | GPS Longitude |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Clearly state the rationale for the choice of tools and technologies for the project.**_\n",
    "\n",
    "I expect the technologies that run the whole process both locally and in the cloud. Therefore, **Apache Spark** is choosen to build the whole data pipeline. I can develop and validate the pipeline locally wiht relative small amount data, then deploy the pipeline to cloud like AWS EMR to work with large amount data. Besides, parquet used by **Apache Spark** can help the performance over the raw data and promise the scalability up to large amount data size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Propose how often the data should be updated and why.**_\n",
    "\n",
    "The ideal schedule of updating data is daily because fact table, immigration data, is partitioned daily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Write a description of how you would approach the problem differently under the following scenarios**_\n",
    "\n",
    "* **The data was increased by 100x.**\n",
    "\n",
    "    As the pipeline is built with **Apache Spark**, it is easy to move the pipeline to cloud like AWS EMR cluster for large amount data. Besides, the cluster can be easily scale out by adding the nodes. In this case, S3 can be consider as the storage for the processed data because the storage capacity can be treated as no limit and the processed data can be distributed globally.\n",
    "\n",
    "\n",
    "* **The data populates a dashboard that must be updated on a daily basis by 7am every day.**\n",
    "\n",
    "    **Apache Airflow** is a good tool to schedule the job to run daily at expected time. As the functions are modulized, it is easily to integrate these functions into airflow dag file and operators.\n",
    "\n",
    "\n",
    "* **The database needed to be accessed by 100+ people.**\n",
    "\n",
    "    We can use either AWS S3 or AWS Redshift to share the data for over 100+ people. It depends on which data format we finally decied to store the processed data. With Redshift, we can provide the read-only permission to different people. With S3, a static page with download features can be hosted on S3 or use labmda wiht cloudflare to provide the api to the other people to download the data. With this method, we can disable the access direct to S3 for security purpose."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
